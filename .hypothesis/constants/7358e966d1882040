# file: C:\Users\MSII\AppData\Roaming\Python\Python314\site-packages\peft\tuners\tuners_utils.py
# hypothesis_version: 6.148.3

['--', '-merged', '.', '.*\\.[^.]*\\.(\\d+)\\.', '.base_layer', '2.5.0', 'ADALORA', 'EetqLinear', 'HQQLinear', 'LORA', 'Linear', 'ParamWrapper', 'PatchedLinear', 'QuantizedLinear', 'RANDLORA', 'Unloading ', 'WQLinear_GEMM', 'W_q', 'XLORA', '_hf_hook', '_only', 'all', 'and merging ', 'base_layer', 'bert', 'bias', 'codebooks', 'config', 'conv1d', 'cpu', 'dataset', 'default', 'ds_shape', 'embed_scale', 'encoder', 'ensure_weight_tying', 'exclude_modules', 'falcon', 'falcon_h1', 'falcon_mamba', 'h', 'in_features', 'in_proj_weight', 'infeatures', 'input_size', 'keys', 'layer', 'layer_idx', 'layers', 'layers_pattern', 'layers_to_transform', 'llama', 'mamba', 'mamba2', 'matched', 'meta', 'model', 'model_type', 'modules_to_save', 'none', 'num_hidden_layers', 'out_features', 'out_proj', 'outfeatures', 'output_size', 'parametrizations', 'peft_config', 'qweight', 'safetensors_file', 'state', 'target_modules', 'target_parameters', 'tie_word_embeddings', 'to_dict', 'unmatched', 'w_bit', 'weight']