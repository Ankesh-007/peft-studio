# file: C:\Users\MSII\AppData\Roaming\Python\Python314\site-packages\peft\peft_model.py
# hypothesis_version: 6.148.3

[0.5, -100, '(', '--', '-peft', '.', '.base_layer', '.weight', '4.36.0', '4.38.0', '4.43.3', '4.56.0.dev0', 'BufferDict', 'LORA', 'None', 'Not supported', 'Params4bit', 'README.md', '_cast_adapter_dtype', '_hf_hook', '_name_or_path', 'adapter_names', 'adapters', 'alora_offsets', 'attention_mask', 'auto', 'balanced_low_0', 'base_model', 'base_model.model.', 'base_model_class', 'bloom', 'cache_dir', 'cache_position', 'classifier', 'config', 'corda', 'cpu', 'dataset', 'decoder_input_ids', 'default', 'device_map', 'directory', 'disk', 'dropout', 'ds_numel', 'ds_shape', 'dtype', 'element_size', 'encoder_outputs', 'end_positions', 'format', 'gemma2', 'gemma3_text', 'get_input_embeddings', 'get_text_config', 'hf_device_map', 'init_lora_weights', 'input_ids', 'input_type_mask', 'inputs_embeds', 'irregular', 'is_loaded_in_4bit', 'is_loaded_in_8bit', 'is_quantized', 'labels', 'library_name', 'llama', 'lora', 'max_memory', 'meta', 'mistral', 'model', 'model_tags', 'model_type', 'modules_to_save', 'mpt', 'name', 'name_or_path', 'offload_dir', 'offload_folder', 'offload_index', 'olora', 'original_devices', 'other', 'output_attentions', 'output_hidden_states', 'parent_library', 'past_key_values', 'peft', 'persimmon', 'phi', 'pissa', 'position_ids', 'pretraining_tp', 'prompt_encoder', 'pt', 'qa_outputs', 'quant_storage', 'quantization_config', 'regression', 'return_dict', 'revision', 'runtime_config', 'safetensors_file', 'score', 'sequential', 'start_positions', 'state_dict', 'subfolder', 'tags', 'task_ids', 'text-generation', 'text_config', 'to_dict', 'token', 'token_type_ids', 'torch.', 'transformers', 'true', 'type', 'use_auth_token', 'use_safetensors', 'vblora_vector_bank', 'weight_name']